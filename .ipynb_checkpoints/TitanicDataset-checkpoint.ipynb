{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Competition Titanic Dataset Learning\n",
    "https://github.com/ramansah/kaggle-titanic/blob/master/Analysis.ipynb\n",
    "\n",
    "https://corpocrat.com/2014/08/29/tutorial-titanic-dataset-machine-learning-for-kaggle/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINNAME = \"train.csv\"\n",
    "TESTNAME = \"test.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def readTrainData():\n",
    "    return pd.read_csv(TRAINNAME)\n",
    "def readTestData():\n",
    "    return pd.read_csv(TESTNAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_all = readTrainData()\n",
    "X_train_len = X_train_all.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_result = readTestData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "survived = X_train_all['Survived']\n",
    "X_train_all.drop('Survived', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([X_train_all, X_result], ignore_index=True, sort =False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1309 entries, 0 to 1308\n",
      "Data columns (total 11 columns):\n",
      "PassengerId    1309 non-null int64\n",
      "Pclass         1309 non-null int64\n",
      "Name           1309 non-null object\n",
      "Sex            1309 non-null object\n",
      "Age            1046 non-null float64\n",
      "SibSp          1309 non-null int64\n",
      "Parch          1309 non-null int64\n",
      "Ticket         1309 non-null object\n",
      "Fare           1308 non-null float64\n",
      "Cabin          295 non-null object\n",
      "Embarked       1307 non-null object\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 112.6+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                               Name  \\\n",
       "0            1       3                            Braund, Mr. Owen Harris   \n",
       "1            2       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2            3       3                             Heikkinen, Miss. Laina   \n",
       "3            4       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4            5       3                           Allen, Mr. William Henry   \n",
       "\n",
       "      Sex   Age  SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "0    male  22.0      1      0         A/5 21171   7.2500   NaN        S  \n",
       "1  female  38.0      1      0          PC 17599  71.2833   C85        C  \n",
       "2  female  26.0      0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3  female  35.0      1      0            113803  53.1000  C123        S  \n",
       "4    male  35.0      0      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1046.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1308.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>655.000000</td>\n",
       "      <td>2.294882</td>\n",
       "      <td>29.881138</td>\n",
       "      <td>0.498854</td>\n",
       "      <td>0.385027</td>\n",
       "      <td>33.295479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>378.020061</td>\n",
       "      <td>0.837836</td>\n",
       "      <td>14.413493</td>\n",
       "      <td>1.041658</td>\n",
       "      <td>0.865560</td>\n",
       "      <td>51.758668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>328.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>655.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>982.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.275000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1309.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId       Pclass          Age        SibSp        Parch  \\\n",
       "count  1309.000000  1309.000000  1046.000000  1309.000000  1309.000000   \n",
       "mean    655.000000     2.294882    29.881138     0.498854     0.385027   \n",
       "std     378.020061     0.837836    14.413493     1.041658     0.865560   \n",
       "min       1.000000     1.000000     0.170000     0.000000     0.000000   \n",
       "25%     328.000000     2.000000    21.000000     0.000000     0.000000   \n",
       "50%     655.000000     3.000000    28.000000     0.000000     0.000000   \n",
       "75%     982.000000     3.000000    39.000000     1.000000     0.000000   \n",
       "max    1309.000000     3.000000    80.000000     8.000000     9.000000   \n",
       "\n",
       "              Fare  \n",
       "count  1308.000000  \n",
       "mean     33.295479  \n",
       "std      51.758668  \n",
       "min       0.000000  \n",
       "25%       7.895800  \n",
       "50%      14.454200  \n",
       "75%      31.275000  \n",
       "max     512.329200  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Data\n",
    "https://corpocrat.com/2014/08/29/tutorial-titanic-dataset-machine-learning-for-kaggle/\n",
    "\n",
    "Need to convert the text fields into numbers to train on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1046.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1308.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.294882</td>\n",
       "      <td>29.881138</td>\n",
       "      <td>0.498854</td>\n",
       "      <td>0.385027</td>\n",
       "      <td>33.295479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.837836</td>\n",
       "      <td>14.413493</td>\n",
       "      <td>1.041658</td>\n",
       "      <td>0.865560</td>\n",
       "      <td>51.758668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.275000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Pclass          Age        SibSp        Parch         Fare\n",
       "count  1309.000000  1046.000000  1309.000000  1309.000000  1308.000000\n",
       "mean      2.294882    29.881138     0.498854     0.385027    33.295479\n",
       "std       0.837836    14.413493     1.041658     0.865560    51.758668\n",
       "min       1.000000     0.170000     0.000000     0.000000     0.000000\n",
       "25%       2.000000    21.000000     0.000000     0.000000     7.895800\n",
       "50%       3.000000    28.000000     0.000000     0.000000    14.454200\n",
       "75%       3.000000    39.000000     1.000000     0.000000    31.275000\n",
       "max       3.000000    80.000000     8.000000     9.000000   512.329200"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop('PassengerId', axis=1, inplace=True)\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "data['Sex'] = LabelEncoder().fit_transform(data['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Mr', 'Mrs', 'Miss', 'Master', 'Don', 'Rev', 'Dr', 'Mme', 'Ms',\n",
       "       'Major', 'Lady', 'Sir', 'Mlle', 'Col', 'Capt', 'the Countess',\n",
       "       'Jonkheer', 'Dona'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Name'] = data['Name'].map(lambda x: x.split(',')[1].split('.')[0].strip())\n",
    "titles = data['Name'].unique()\n",
    "titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Mr</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Miss</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Mr</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Name  Sex   Age  SibSp  Parch            Ticket     Fare Cabin  \\\n",
       "0       3    Mr    1  22.0      1      0         A/5 21171   7.2500   NaN   \n",
       "1       1   Mrs    0  38.0      1      0          PC 17599  71.2833   C85   \n",
       "2       3  Miss    0  26.0      0      0  STON/O2. 3101282   7.9250   NaN   \n",
       "3       1   Mrs    0  35.0      1      0            113803  53.1000  C123   \n",
       "4       3    Mr    1  35.0      0      0            373450   8.0500   NaN   \n",
       "\n",
       "  Embarked  \n",
       "0        S  \n",
       "1        C  \n",
       "2        S  \n",
       "3        S  \n",
       "4        S  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Age'].fillna(-1, inplace=True)\n",
    "\n",
    "medians = dict()\n",
    "for title in titles:\n",
    "    median = data.Age[(data[\"Age\"] != -1) & (data['Name'] == title)].median()\n",
    "    medians[title] = median\n",
    "    \n",
    "for index, row in data.iterrows():\n",
    "    if row['Age'] == -1:\n",
    "        data.loc[index, 'Age'] = medians[row['Name']]\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacement = {\n",
    "    'Don': 0,\n",
    "    'Rev': 0,\n",
    "    'Jonkheer': 0,\n",
    "    'Capt': 0,\n",
    "    'Mr': 1,\n",
    "    'Dr': 2,\n",
    "    'Col': 3,\n",
    "    'Major': 3,\n",
    "    'Master': 4,\n",
    "    'Miss': 5,\n",
    "    'Mrs': 6,\n",
    "    'Mme': 7,\n",
    "    'Ms': 7,\n",
    "    'Mlle': 7,\n",
    "    'Sir': 7,\n",
    "    'Lady': 7,\n",
    "    'the Countess': 7\n",
    "}\n",
    "\n",
    "data['Name'] = data['Name'].apply(lambda x: replacement.get(x))\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "data['Name'] = StandardScaler().fit_transform(data['Name'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass   Age  SibSp  Parch            Ticket Cabin Embarked\n",
       "0       3  22.0      1      0         A/5 21171   NaN        S\n",
       "1       1  38.0      1      0          PC 17599   C85        C\n",
       "2       3  26.0      0      0  STON/O2. 3101282   NaN        S\n",
       "3       1  35.0      1      0            113803  C123        S\n",
       "4       3  35.0      0      0            373450   NaN        S"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()[['Pclass', 'Age', 'SibSp', 'Parch', 'Ticket', 'Cabin', 'Embarked']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "data['Age'] = StandardScaler().fit_transform(data['Age'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Fare'].fillna(-1, inplace=True)\n",
    "medians = dict()\n",
    "for pclass in data['Pclass'].unique():\n",
    "    median = data.Fare[(data[\"Fare\"] != -1) & (data['Pclass'] == pclass)].median()\n",
    "    medians[pclass] = median\n",
    "for index, row in data.iterrows():\n",
    "    if row['Fare'] == -1:\n",
    "        data.loc[index, 'Fare'] = medians[row['Pclass']]\n",
    "data['Fare'] = StandardScaler().fit_transform(data['Fare'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Pclass'] = StandardScaler().fit_transform(data['Pclass'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacement = {\n",
    "    6: 0,\n",
    "    4: 0,\n",
    "    5: 1,\n",
    "    0: 2,\n",
    "    2: 3,\n",
    "    1: 4,\n",
    "    3: 5\n",
    "}\n",
    "data['Parch'] = data['Parch'].apply(lambda x: replacement.get(x))\n",
    "data['Parch'] = StandardScaler().fit_transform(data['Parch'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('Ticket', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Embarked'].fillna('S', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   -0.622279\n",
       "1    1.834926\n",
       "2   -0.622279\n",
       "3   -0.622279\n",
       "4   -0.622279\n",
       "Name: Embarked, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replacement = {\n",
    "    'S': 0,\n",
    "    'Q': 1,\n",
    "    'C': 2\n",
    "}\n",
    "\n",
    "data['Embarked'] = data['Embarked'].apply(lambda x: replacement.get(x))\n",
    "data['Embarked'] = StandardScaler().fit_transform(data['Embarked'].values.reshape(-1, 1))\n",
    "data.head()['Embarked']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 3, 4, 2, 5, 8])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['SibSp'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.562046\n",
       "1    1.562046\n",
       "2   -0.435725\n",
       "3    1.562046\n",
       "4   -0.435725\n",
       "Name: SibSp, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replacement = {\n",
    "    5: 0,\n",
    "    8: 0,\n",
    "    4: 1,\n",
    "    3: 2,\n",
    "    0: 3,\n",
    "    2: 4,\n",
    "    1: 5\n",
    "}\n",
    "\n",
    "data['SibSp'] = data['SibSp'].apply(lambda x: replacement.get(x))\n",
    "data['SibSp'] = StandardScaler().fit_transform(data['SibSp'].values.reshape(-1, 1))\n",
    "data.head()['SibSp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['U', 'C', 'E', 'G', 'D', 'A', 'B', 'F', 'T'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Cabin'].fillna('U', inplace=True)\n",
    "data['Cabin'] = data['Cabin'].apply(lambda x: x[0])\n",
    "data['Cabin'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   -0.489356\n",
       "1    1.000334\n",
       "2   -0.489356\n",
       "3    1.000334\n",
       "4   -0.489356\n",
       "Name: Cabin, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replacement = {\n",
    "    'T': 0,\n",
    "    'U': 1,\n",
    "    'A': 2,\n",
    "    'G': 3,\n",
    "    'C': 4,\n",
    "    'F': 5,\n",
    "    'B': 6,\n",
    "    'E': 7,\n",
    "    'D': 8\n",
    "}\n",
    "\n",
    "data['Cabin'] = data['Cabin'].apply(lambda x: replacement.get(x))\n",
    "data['Cabin'] = StandardScaler().fit_transform(data['Cabin'].values.reshape(-1, 1))\n",
    "data.head()['Cabin']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    data.head(X_train_len), survived, test_size=150, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = data.head(data.shape[0]- X_train_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>0.841916</td>\n",
       "      <td>-0.805647</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.032869</td>\n",
       "      <td>-0.435725</td>\n",
       "      <td>-0.461223</td>\n",
       "      <td>-0.474901</td>\n",
       "      <td>-0.489356</td>\n",
       "      <td>1.834926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>0.841916</td>\n",
       "      <td>-0.805647</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.412845</td>\n",
       "      <td>-0.435725</td>\n",
       "      <td>-0.461223</td>\n",
       "      <td>-0.498424</td>\n",
       "      <td>-0.489356</td>\n",
       "      <td>-0.622279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>0.841916</td>\n",
       "      <td>-0.805647</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.868816</td>\n",
       "      <td>-0.435725</td>\n",
       "      <td>-0.461223</td>\n",
       "      <td>-0.492624</td>\n",
       "      <td>-0.489356</td>\n",
       "      <td>-0.622279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0.841916</td>\n",
       "      <td>1.055344</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.564835</td>\n",
       "      <td>1.562046</td>\n",
       "      <td>-0.461223</td>\n",
       "      <td>-0.176441</td>\n",
       "      <td>-0.489356</td>\n",
       "      <td>0.606323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.841916</td>\n",
       "      <td>-0.805647</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.032869</td>\n",
       "      <td>-0.435725</td>\n",
       "      <td>-0.461223</td>\n",
       "      <td>-0.487709</td>\n",
       "      <td>-0.489356</td>\n",
       "      <td>-0.622279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pclass      Name  Sex       Age     SibSp     Parch      Fare  \\\n",
       "584  0.841916 -0.805647    1 -0.032869 -0.435725 -0.461223 -0.474901   \n",
       "514  0.841916 -0.805647    1 -0.412845 -0.435725 -0.461223 -0.498424   \n",
       "688  0.841916 -0.805647    1 -0.868816 -0.435725 -0.461223 -0.492624   \n",
       "109  0.841916  1.055344    0 -0.564835  1.562046 -0.461223 -0.176441   \n",
       "77   0.841916 -0.805647    1 -0.032869 -0.435725 -0.461223 -0.487709   \n",
       "\n",
       "        Cabin  Embarked  \n",
       "584 -0.489356  1.834926  \n",
       "514 -0.489356 -0.622279  \n",
       "688 -0.489356 -0.622279  \n",
       "109 -0.489356  0.606323  \n",
       "77  -0.489356 -0.622279  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.053529</td>\n",
       "      <td>0.049162</td>\n",
       "      <td>0.617225</td>\n",
       "      <td>-0.081003</td>\n",
       "      <td>-0.065325</td>\n",
       "      <td>0.007872</td>\n",
       "      <td>-0.014590</td>\n",
       "      <td>-0.031995</td>\n",
       "      <td>-0.031492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.981475</td>\n",
       "      <td>0.994390</td>\n",
       "      <td>0.486647</td>\n",
       "      <td>0.985755</td>\n",
       "      <td>1.055403</td>\n",
       "      <td>0.978795</td>\n",
       "      <td>0.953682</td>\n",
       "      <td>0.962404</td>\n",
       "      <td>0.978207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.546098</td>\n",
       "      <td>-1.270895</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.173652</td>\n",
       "      <td>-3.432380</td>\n",
       "      <td>-3.110977</td>\n",
       "      <td>-0.643344</td>\n",
       "      <td>-0.985919</td>\n",
       "      <td>-0.622279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.352091</td>\n",
       "      <td>-0.805647</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.564835</td>\n",
       "      <td>-0.435725</td>\n",
       "      <td>-0.461223</td>\n",
       "      <td>-0.490126</td>\n",
       "      <td>-0.489356</td>\n",
       "      <td>-0.622279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.841916</td>\n",
       "      <td>-0.805647</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.032869</td>\n",
       "      <td>-0.435725</td>\n",
       "      <td>-0.461223</td>\n",
       "      <td>-0.363894</td>\n",
       "      <td>-0.489356</td>\n",
       "      <td>-0.622279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.841916</td>\n",
       "      <td>1.055344</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.451599</td>\n",
       "      <td>0.563161</td>\n",
       "      <td>-0.461223</td>\n",
       "      <td>-0.045477</td>\n",
       "      <td>-0.489356</td>\n",
       "      <td>0.606323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.841916</td>\n",
       "      <td>1.985840</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.158926</td>\n",
       "      <td>1.562046</td>\n",
       "      <td>3.513407</td>\n",
       "      <td>9.261749</td>\n",
       "      <td>2.986588</td>\n",
       "      <td>1.834926</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Pclass        Name         Sex         Age       SibSp       Parch  \\\n",
       "count  418.000000  418.000000  418.000000  418.000000  418.000000  418.000000   \n",
       "mean     0.053529    0.049162    0.617225   -0.081003   -0.065325    0.007872   \n",
       "std      0.981475    0.994390    0.486647    0.985755    1.055403    0.978795   \n",
       "min     -1.546098   -1.270895    0.000000   -2.173652   -3.432380   -3.110977   \n",
       "25%     -0.352091   -0.805647    0.000000   -0.564835   -0.435725   -0.461223   \n",
       "50%      0.841916   -0.805647    1.000000   -0.032869   -0.435725   -0.461223   \n",
       "75%      0.841916    1.055344    1.000000    0.451599    0.563161   -0.461223   \n",
       "max      0.841916    1.985840    1.000000    3.158926    1.562046    3.513407   \n",
       "\n",
       "             Fare       Cabin    Embarked  \n",
       "count  418.000000  418.000000  418.000000  \n",
       "mean    -0.014590   -0.031995   -0.031492  \n",
       "std      0.953682    0.962404    0.978207  \n",
       "min     -0.643344   -0.985919   -0.622279  \n",
       "25%     -0.490126   -0.489356   -0.622279  \n",
       "50%     -0.363894   -0.489356   -0.622279  \n",
       "75%     -0.045477   -0.489356    0.606323  \n",
       "max      9.261749    2.986588    1.834926  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using GridSearchCV on RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "rdm_fst = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trees = [500,1000,5000]\n",
    "num_samples = [2]\n",
    "tuned_parameters = [{'n_estimators': num_trees,'min_samples_split':num_samples}]\n",
    "grid_search = GridSearchCV(rdm_fst, tuned_parameters, scoring = 'accuracy', cv=20, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 20 folds for each of 3 candidates, totalling 60 fits\n",
      "[CV] min_samples_split=2, n_estimators=500 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  min_samples_split=2, n_estimators=500, score=0.763, total=   0.7s\n",
      "[CV] min_samples_split=2, n_estimators=500 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  min_samples_split=2, n_estimators=500, score=0.865, total=   0.6s\n",
      "[CV] min_samples_split=2, n_estimators=500 ...........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  min_samples_split=2, n_estimators=500, score=0.811, total=   0.6s\n",
      "[CV] min_samples_split=2, n_estimators=500 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=500, score=0.865, total=   0.7s\n",
      "[CV] min_samples_split=2, n_estimators=500 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=500, score=0.622, total=   0.7s\n",
      "[CV] min_samples_split=2, n_estimators=500 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=500, score=0.811, total=   0.6s\n",
      "[CV] min_samples_split=2, n_estimators=500 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=500, score=0.838, total=   0.6s\n",
      "[CV] min_samples_split=2, n_estimators=500 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=500, score=0.838, total=   0.5s\n",
      "[CV] min_samples_split=2, n_estimators=500 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=500, score=0.892, total=   0.5s\n",
      "[CV] min_samples_split=2, n_estimators=500 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=500, score=0.811, total=   0.5s\n",
      "[CV] min_samples_split=2, n_estimators=500 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=500, score=0.811, total=   0.5s\n",
      "[CV] min_samples_split=2, n_estimators=500 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=500, score=0.838, total=   0.5s\n",
      "[CV] min_samples_split=2, n_estimators=500 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=500, score=0.730, total=   0.7s\n",
      "[CV] min_samples_split=2, n_estimators=500 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=500, score=0.784, total=   0.7s\n",
      "[CV] min_samples_split=2, n_estimators=500 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=500, score=0.784, total=   0.6s\n",
      "[CV] min_samples_split=2, n_estimators=500 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=500, score=0.919, total=   0.8s\n",
      "[CV] min_samples_split=2, n_estimators=500 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=500, score=0.811, total=   0.6s\n",
      "[CV] min_samples_split=2, n_estimators=500 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=500, score=0.811, total=   0.5s\n",
      "[CV] min_samples_split=2, n_estimators=500 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=500, score=0.946, total=   0.6s\n",
      "[CV] min_samples_split=2, n_estimators=500 ...........................\n",
      "[CV]  min_samples_split=2, n_estimators=500, score=0.892, total=   0.7s\n",
      "[CV] min_samples_split=2, n_estimators=1000 ..........................\n",
      "[CV]  min_samples_split=2, n_estimators=1000, score=0.763, total=   1.0s\n",
      "[CV] min_samples_split=2, n_estimators=1000 ..........................\n",
      "[CV]  min_samples_split=2, n_estimators=1000, score=0.865, total=   1.2s\n",
      "[CV] min_samples_split=2, n_estimators=1000 ..........................\n",
      "[CV]  min_samples_split=2, n_estimators=1000, score=0.811, total=   2.3s\n",
      "[CV] min_samples_split=2, n_estimators=1000 ..........................\n",
      "[CV]  min_samples_split=2, n_estimators=1000, score=0.865, total=   1.3s\n",
      "[CV] min_samples_split=2, n_estimators=1000 ..........................\n",
      "[CV]  min_samples_split=2, n_estimators=1000, score=0.676, total=   1.2s\n",
      "[CV] min_samples_split=2, n_estimators=1000 ..........................\n",
      "[CV]  min_samples_split=2, n_estimators=1000, score=0.811, total=   2.0s\n",
      "[CV] min_samples_split=2, n_estimators=1000 ..........................\n",
      "[CV]  min_samples_split=2, n_estimators=1000, score=0.811, total=   1.8s\n",
      "[CV] min_samples_split=2, n_estimators=1000 ..........................\n",
      "[CV]  min_samples_split=2, n_estimators=1000, score=0.838, total=   1.2s\n",
      "[CV] min_samples_split=2, n_estimators=1000 ..........................\n",
      "[CV]  min_samples_split=2, n_estimators=1000, score=0.892, total=   1.5s\n",
      "[CV] min_samples_split=2, n_estimators=1000 ..........................\n",
      "[CV]  min_samples_split=2, n_estimators=1000, score=0.838, total=   1.7s\n",
      "[CV] min_samples_split=2, n_estimators=1000 ..........................\n",
      "[CV]  min_samples_split=2, n_estimators=1000, score=0.811, total=   1.3s\n",
      "[CV] min_samples_split=2, n_estimators=1000 ..........................\n",
      "[CV]  min_samples_split=2, n_estimators=1000, score=0.811, total=   1.2s\n",
      "[CV] min_samples_split=2, n_estimators=1000 ..........................\n",
      "[CV]  min_samples_split=2, n_estimators=1000, score=0.730, total=   1.2s\n",
      "[CV] min_samples_split=2, n_estimators=1000 ..........................\n",
      "[CV]  min_samples_split=2, n_estimators=1000, score=0.784, total=   1.2s\n",
      "[CV] min_samples_split=2, n_estimators=1000 ..........................\n",
      "[CV]  min_samples_split=2, n_estimators=1000, score=0.784, total=   1.1s\n",
      "[CV] min_samples_split=2, n_estimators=1000 ..........................\n",
      "[CV]  min_samples_split=2, n_estimators=1000, score=0.919, total=   1.1s\n",
      "[CV] min_samples_split=2, n_estimators=1000 ..........................\n",
      "[CV]  min_samples_split=2, n_estimators=1000, score=0.811, total=   1.1s\n",
      "[CV] min_samples_split=2, n_estimators=1000 ..........................\n",
      "[CV]  min_samples_split=2, n_estimators=1000, score=0.811, total=   1.1s\n",
      "[CV] min_samples_split=2, n_estimators=1000 ..........................\n",
      "[CV]  min_samples_split=2, n_estimators=1000, score=0.946, total=   1.1s\n",
      "[CV] min_samples_split=2, n_estimators=1000 ..........................\n",
      "[CV]  min_samples_split=2, n_estimators=1000, score=0.865, total=   1.2s\n",
      "[CV] min_samples_split=2, n_estimators=5000 ..........................\n",
      "[CV]  min_samples_split=2, n_estimators=5000, score=0.789, total=   5.6s\n",
      "[CV] min_samples_split=2, n_estimators=5000 ..........................\n",
      "[CV]  min_samples_split=2, n_estimators=5000, score=0.865, total=   5.5s\n",
      "[CV] min_samples_split=2, n_estimators=5000 ..........................\n",
      "[CV]  min_samples_split=2, n_estimators=5000, score=0.811, total=   7.4s\n",
      "[CV] min_samples_split=2, n_estimators=5000 ..........................\n",
      "[CV]  min_samples_split=2, n_estimators=5000, score=0.865, total=   5.6s\n",
      "[CV] min_samples_split=2, n_estimators=5000 ..........................\n",
      "[CV]  min_samples_split=2, n_estimators=5000, score=0.676, total=   5.5s\n",
      "[CV] min_samples_split=2, n_estimators=5000 ..........................\n",
      "[CV]  min_samples_split=2, n_estimators=5000, score=0.811, total=   5.5s\n",
      "[CV] min_samples_split=2, n_estimators=5000 ..........................\n",
      "[CV]  min_samples_split=2, n_estimators=5000, score=0.811, total=   5.5s\n",
      "[CV] min_samples_split=2, n_estimators=5000 ..........................\n",
      "[CV]  min_samples_split=2, n_estimators=5000, score=0.838, total=   5.4s\n",
      "[CV] min_samples_split=2, n_estimators=5000 ..........................\n",
      "[CV]  min_samples_split=2, n_estimators=5000, score=0.892, total=   5.8s\n",
      "[CV] min_samples_split=2, n_estimators=5000 ..........................\n",
      "[CV]  min_samples_split=2, n_estimators=5000, score=0.811, total=   5.4s\n",
      "[CV] min_samples_split=2, n_estimators=5000 ..........................\n",
      "[CV]  min_samples_split=2, n_estimators=5000, score=0.811, total=   5.5s\n",
      "[CV] min_samples_split=2, n_estimators=5000 ..........................\n",
      "[CV]  min_samples_split=2, n_estimators=5000, score=0.811, total=   5.3s\n",
      "[CV] min_samples_split=2, n_estimators=5000 ..........................\n",
      "[CV]  min_samples_split=2, n_estimators=5000, score=0.730, total=   5.4s\n",
      "[CV] min_samples_split=2, n_estimators=5000 ..........................\n",
      "[CV]  min_samples_split=2, n_estimators=5000, score=0.784, total=   5.3s\n",
      "[CV] min_samples_split=2, n_estimators=5000 ..........................\n",
      "[CV]  min_samples_split=2, n_estimators=5000, score=0.811, total=   5.4s\n",
      "[CV] min_samples_split=2, n_estimators=5000 ..........................\n",
      "[CV]  min_samples_split=2, n_estimators=5000, score=0.919, total=   5.4s\n",
      "[CV] min_samples_split=2, n_estimators=5000 ..........................\n",
      "[CV]  min_samples_split=2, n_estimators=5000, score=0.811, total=   5.6s\n",
      "[CV] min_samples_split=2, n_estimators=5000 ..........................\n",
      "[CV]  min_samples_split=2, n_estimators=5000, score=0.811, total=   5.5s\n",
      "[CV] min_samples_split=2, n_estimators=5000 ..........................\n",
      "[CV]  min_samples_split=2, n_estimators=5000, score=0.946, total=   5.8s\n",
      "[CV] min_samples_split=2, n_estimators=5000 ..........................\n",
      "[CV]  min_samples_split=2, n_estimators=5000, score=0.892, total=   5.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:  2.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=20, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators='warn', n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid=[{'min_samples_split': [2],\n",
       "                          'n_estimators': [500, 1000, 5000]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=3)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_samples_split': 2, 'n_estimators': 5000}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8245614035087719"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".1, 1000\n",
    "\n",
    "0.08, 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9811066126855601"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model = grid_search.best_estimator_\n",
    "final_model.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.score(X_val,y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8852901484480432"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "clf = ensemble.GradientBoostingClassifier(n_estimators=50)\n",
    "clf.fit(X_train,y_train)\n",
    "clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_val,y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using an ensemble learner with RandomForest, ExtraTrees and MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_clf = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "extra_trees_clf = ExtraTreesClassifier(n_estimators=10, random_state=42)\n",
    "mlp_clf = MLPClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
      "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
      "                       warm_start=False)\n",
      "Training the ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "                     max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                     min_samples_leaf=1, min_samples_split=2,\n",
      "                     min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "                     oob_score=False, random_state=42, verbose=0,\n",
      "                     warm_start=False)\n",
      "Training the MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "              random_state=42, shuffle=True, solver='adam', tol=0.0001,\n",
      "              validation_fraction=0.1, verbose=False, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "estimators = [random_forest_clf, extra_trees_clf, mlp_clf]\n",
    "for estimator in estimators:\n",
    "    print(\"Training the\", estimator)\n",
    "    estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8533333333333334, 0.8266666666666667, 0.84]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[estimator.score(X_val, y_val) for estimator in estimators]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "named_estimators = [\n",
    "    (\"random_forest_clf\", random_forest_clf),\n",
    "    (\"extra_trees_clf\", extra_trees_clf),\n",
    "    (\"mlp_clf\", mlp_clf),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf = VotingClassifier(named_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('random_forest_clf',\n",
       "                              RandomForestClassifier(bootstrap=True,\n",
       "                                                     class_weight=None,\n",
       "                                                     criterion='gini',\n",
       "                                                     max_depth=None,\n",
       "                                                     max_features='auto',\n",
       "                                                     max_leaf_nodes=None,\n",
       "                                                     min_impurity_decrease=0.0,\n",
       "                                                     min_impurity_split=None,\n",
       "                                                     min_samples_leaf=1,\n",
       "                                                     min_samples_split=2,\n",
       "                                                     min_weight_fraction_leaf=0.0,\n",
       "                                                     n_estimators=10,\n",
       "                                                     n_jobs=None,\n",
       "                                                     oob_score=False,\n",
       "                                                     random_sta...\n",
       "                                            beta_2=0.999, early_stopping=False,\n",
       "                                            epsilon=1e-08,\n",
       "                                            hidden_layer_sizes=(100,),\n",
       "                                            learning_rate='constant',\n",
       "                                            learning_rate_init=0.001,\n",
       "                                            max_iter=200, momentum=0.9,\n",
       "                                            n_iter_no_change=10,\n",
       "                                            nesterovs_momentum=True,\n",
       "                                            power_t=0.5, random_state=42,\n",
       "                                            shuffle=True, solver='adam',\n",
       "                                            tol=0.0001, validation_fraction=0.1,\n",
       "                                            verbose=False, warm_start=False))],\n",
       "                 flatten_transform=True, n_jobs=None, voting='hard',\n",
       "                 weights=None)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9689608636977058"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf.voting = \"soft\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8466666666666667"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_results_search = final_model.predict(X_test)\n",
    "y_results_boost = final_model.predict(X_test)\n",
    "y_results_ensemble = final_model.predict(X_test)\n",
    "\n",
    "final_predictions = y_results_ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = np.column_stack((X_result[\"PassengerId\"],final_predictions))\n",
    "df_results = pd.DataFrame(output.astype('int'),columns=['PassengerID','Survived'])\n",
    "df_results.to_csv('titanic_results.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
